{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_ex_5_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1VElIp4e4JcB9ksGASBh47ixN8hkUx8Y3",
      "authorship_tag": "ABX9TyMMDZT8NrXRwoHHos6UGZsQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shon-otmazgin/gcommand_recognition_cnn/blob/main/vgg11_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ioRzEoCRCxY"
      },
      "source": [
        "!rm -rf gcommands\r\n",
        "!rm -rf gcommand_dataset.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p24UPJGvN03G"
      },
      "source": [
        "# copy the data files + gcommand_dataset_cnn.py\r\n",
        "# data files:\r\n",
        "# https://drive.google.com/file/d/1Gqo0pQxuRysNtKecDBk_jvk8zK4BrYbR/view\r\n",
        "# ‘gcommand_dataset_cnn.py’:\r\n",
        "# https://drive.google.com/file/d/1JyQWSOTfPtyCV8O9_XoE0Q5W5dqtMaav/view?usp=sharing\r\n",
        "# Notebook:\r\n",
        "# https://drive.google.com/file/d/1VElIp4e4JcB9ksGASBh47ixN8hkUx8Y3/view?usp=sharing\r\n",
        "\r\n",
        "!cp drive/MyDrive/Colab\\ Notebooks/gcommand_dataset_cnn.py gcommand_dataset_cnn.py\r\n",
        "!unzip -qq drive/MyDrive/ex5_data.zip -d gcommands"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJHBJxrERcjW",
        "outputId": "a8008d8b-3663-41c3-c141-76b26b89d013"
      },
      "source": [
        "# create test dir under test dir. this is the fix Yossi mentioned in the piazza\r\n",
        "\r\n",
        "!mkdir gcommands/test/test/\r\n",
        "!mv gcommands/test/* gcommands/test/test/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot move 'gcommands/test/test' to a subdirectory of itself, 'gcommands/test/test/test'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNUAlWR_PA_X"
      },
      "source": [
        "from gcommand_dataset_cnn import GCommandLoader\r\n",
        "import torch\r\n",
        "from torch import optim\r\n",
        "import torch.nn as nn\r\n",
        "from torch.functional import F\r\n",
        "import numpy as np\r\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K4CGr05TEoA"
      },
      "source": [
        "def train(model, optimizer, train_loader, val_loader, epochs=10):\r\n",
        "    global device\r\n",
        "    train_loss = 0\r\n",
        "    train_correct = 0\r\n",
        "    for e in range(epochs):\r\n",
        "        model.train()\r\n",
        "        for batch_idx, (data, labels) in enumerate(train_loader):\r\n",
        "            data, labels = data.to(device), labels.to(device)\r\n",
        "            \r\n",
        "            optimizer.zero_grad()\r\n",
        "            output = model(data)\r\n",
        "            \r\n",
        "            loss = F.nll_loss(input=output, target=labels)\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "            train_loss += loss.item()\r\n",
        "            pred = output.max(dim=1, keepdim=True)[1]  # get the index of the max log-probability\r\n",
        "            train_correct += pred.eq(labels.view_as(pred)).cpu().sum().item()\r\n",
        "\r\n",
        "        train_loss /= len(train_loader.dataset)\r\n",
        "        train_correct /= len(train_loader.dataset)\r\n",
        "        if val_loader:\r\n",
        "            val_loss, val_acc = test(model=model, loader=val_loader)\r\n",
        "        else:\r\n",
        "            val_loss, val_acc = None, None\r\n",
        "\r\n",
        "        print(f'Epoch: {e + 1} [{(e + 1)}/{epochs}] Train Loss: {train_loss:.3f}, Val Loss: {val_loss:.3f}')\r\n",
        "        print(f'Epoch: {e + 1} [{(e + 1)}/{epochs}] Train ACC:  {train_correct:.3f},  Val ACC:  {val_acc:.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5eYW_tVTb02"
      },
      "source": [
        "def test(model, loader):\r\n",
        "    global device\r\n",
        "    model.eval()\r\n",
        "    loss = 0\r\n",
        "    correct = 0\r\n",
        "    with torch.no_grad():\r\n",
        "        for data, target in loader:\r\n",
        "            data, target = data.to(device), target.to(device)\r\n",
        "            \r\n",
        "            output = model(data)\r\n",
        "            loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\r\n",
        "            pred = output.max(dim=1, keepdim=True)[1]  # get the index of the max log-probability\r\n",
        "            correct += pred.eq(target.view_as(pred)).cpu().sum().item()\r\n",
        "\r\n",
        "    loss /= len(loader.dataset)\r\n",
        "    return loss, correct / len(loader.dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKTOnfe51eGF"
      },
      "source": [
        "def _make_layers(cfg):\r\n",
        "    layers = []\r\n",
        "    in_channels = 1\r\n",
        "    for x in cfg:\r\n",
        "        if x == 'M':\r\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\r\n",
        "        else:\r\n",
        "            layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\r\n",
        "                       nn.BatchNorm2d(x),\r\n",
        "                       nn.ReLU(inplace=True)]\r\n",
        "            in_channels = x\r\n",
        "    layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\r\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rxk2bIAVgeC"
      },
      "source": [
        "class CNN(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        super(CNN, self).__init__()\r\n",
        "\r\n",
        "        arch = [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\r\n",
        "\r\n",
        "        self.conv = _make_layers(arch)\r\n",
        "        self.fc1 = nn.Linear(7680, 512)\r\n",
        "        self.fc2 = nn.Linear(512, 30)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.conv(x)\r\n",
        "     \r\n",
        "        x = x.view(x.size(0), -1)\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = self.fc2(x)\r\n",
        "        \r\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvGviuu5VgIS"
      },
      "source": [
        "train_set = GCommandLoader('gcommands/train')\r\n",
        "val_set = GCommandLoader('gcommands/valid')\r\n",
        "test_set = GCommandLoader('gcommands/test')\r\n",
        "\r\n",
        "batch_size = 100\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "if device == \"cuda\":\r\n",
        "    num_workers = 1\r\n",
        "    pin_memory = True\r\n",
        "else:\r\n",
        "    num_workers = 0\r\n",
        "    pin_memory = False\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\r\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\r\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe1lPVbRlxWU",
        "outputId": "dc8cc368-618d-458c-b149-c05b07b029aa"
      },
      "source": [
        "print(len(train_loader.dataset))\r\n",
        "print(len(val_loader.dataset))\r\n",
        "print(len(test_loader.dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30000\n",
            "6798\n",
            "6835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV-O3itPSufp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcfb95cb-230a-41bc-d29f-a031355dfc75"
      },
      "source": [
        "epochs = 7\r\n",
        "\r\n",
        "model = CNN()\r\n",
        "model.to(device)\r\n",
        "\r\n",
        "adam = optim.Adam(model.parameters(), lr=0.0001)\r\n",
        "train(model=model, optimizer=adam, train_loader=train_loader, val_loader=val_loader, epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 [1/7] Train Loss: 0.009, Val Loss: 0.383\n",
            "Epoch: 1 [1/7] Train ACC:  0.761,  Val ACC:  0.884\n",
            "Epoch: 2 [2/7] Train Loss: 0.002, Val Loss: 0.358\n",
            "Epoch: 2 [2/7] Train ACC:  0.942,  Val ACC:  0.896\n",
            "Epoch: 3 [3/7] Train Loss: 0.001, Val Loss: 0.309\n",
            "Epoch: 3 [3/7] Train ACC:  0.963,  Val ACC:  0.913\n",
            "Epoch: 4 [4/7] Train Loss: 0.001, Val Loss: 0.297\n",
            "Epoch: 4 [4/7] Train ACC:  0.976,  Val ACC:  0.918\n",
            "Epoch: 5 [5/7] Train Loss: 0.001, Val Loss: 0.267\n",
            "Epoch: 5 [5/7] Train ACC:  0.983,  Val ACC:  0.925\n",
            "Epoch: 6 [6/7] Train Loss: 0.000, Val Loss: 0.432\n",
            "Epoch: 6 [6/7] Train ACC:  0.987,  Val ACC:  0.896\n",
            "Epoch: 7 [7/7] Train Loss: 0.000, Val Loss: 0.346\n",
            "Epoch: 7 [7/7] Train ACC:  0.992,  Val ACC:  0.915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXywASe9-Hi5"
      },
      "source": [
        "def predict(model, loader):\r\n",
        "    preds = []\r\n",
        "    model.eval()\r\n",
        "    with torch.no_grad():\r\n",
        "        for data, labels in loader:\r\n",
        "            data, labels = data.to(device), labels.to(device)\r\n",
        "            \r\n",
        "            output = model(data)\r\n",
        "            preds.append(output.max(dim=1, keepdim=True)[1])\r\n",
        "\r\n",
        "    return torch.cat(preds, dim=0).detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo7nj4d-A3Ym"
      },
      "source": [
        "y_hat = predict(model=model, loader=test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4IMhhPFH89d"
      },
      "source": [
        "index_2_classes = {i:c for c, i in train_loader.dataset.class_to_idx.items()}\r\n",
        "if sys.platform == 'linux':\r\n",
        "    X = [x.rsplit('/', 1)[1] for x, y in test_loader.dataset.spects]\r\n",
        "else:\r\n",
        "    X = [x.rsplit('\\\\', 1)[1] for x, y in test_loader.dataset.spects]\r\n",
        "output = [f'{x},{index_2_classes[y.item()]}\\n' for x, y in zip(X, y_hat)]\r\n",
        "output = sorted(output, key=lambda x: int(x.split('.')[0]))\r\n",
        "with open('test_y', 'w') as f:\r\n",
        "    f.writelines(output)\r\n",
        "!cp test_y drive/MyDrive/Colab\\ Notebooks/test_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP2cYsfOzM3c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}